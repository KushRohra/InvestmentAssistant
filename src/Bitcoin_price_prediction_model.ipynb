{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51344e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6690af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp\tOpen\tHigh\tLow\tClose\tVolume_(BTC)\tVolume_(Currency)\tWeighted_Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6c14f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c15ac20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.sql.functions import dayofweek, hour\n",
    "from pyspark.sql.functions import lag\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae399f7",
   "metadata": {},
   "source": [
    "# Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3616872",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"BitcoinDataProcessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166af6ad",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b641b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data_full = spark.read.csv(\"./bitcoin_historic_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0caa2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data = bitcoin_data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f3de5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Close    1243608\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_data_full.toPandas()[['Close']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90cf01c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4857377"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_data_full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee64fb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bitcoin_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57841ed8",
   "metadata": {},
   "source": [
    "# Data Cleaning - Time stamp correction, Missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2798f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the timestamp from unixtimestamp to a readable format\n",
    "bitcoin_data = bitcoin_data.withColumn(\"Timestamp\", bitcoin_data[\"Timestamp\"].cast(\"timestamp\"))\n",
    "\n",
    "# Extracting the date part from the timestamp\n",
    "bitcoin_data = bitcoin_data.withColumn(\"Date\", F.to_date(\"Timestamp\"))\n",
    "\n",
    "# Define a window specification partitioned by date and ordered by timestamp\n",
    "window_spec = Window.partitionBy(\"Date\").orderBy(\"Timestamp\")\n",
    "\n",
    "# Getting the first record of each day\n",
    "bitcoin_data = bitcoin_data.withColumn(\"row_num\", F.row_number().over(window_spec)).filter(F.col(\"row_num\") == 1).drop(\"row_num\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fdb7db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Close    675\n",
       " dtype: int64,\n",
       " Close    2700\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_data.toPandas()[['Close']].isnull().sum(), bitcoin_data.toPandas()[['Close']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6a8ca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+----------+\n",
      "|          Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|      Date|\n",
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+----------+\n",
      "|2011-12-31 13:22:00|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|2011-12-31|\n",
      "|2012-01-01 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-01|\n",
      "|2012-01-02 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-02|\n",
      "|2012-01-03 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-03|\n",
      "|2012-01-04 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-04|\n",
      "|2012-01-05 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-05|\n",
      "|2012-01-06 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-06|\n",
      "|2012-01-07 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-07|\n",
      "|2012-01-08 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-08|\n",
      "|2012-01-09 00:00:00| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2012-01-09|\n",
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bitcoin_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89845f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3375"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ede3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, last\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "other_columns = [\"Weighted_Price\", \"Volume_(BTC)\", \"Volume_(Currency)\"]\n",
    "for col_name in other_columns:\n",
    "#     bitcoin_data = bitcoin_data.withColumn(col_name, when(col(col_name).isNull(), 0).otherwise(col(col_name)))\n",
    "    bitcoin_data = bitcoin_data.na.fill(value=0,subset=[col_name])\n",
    "\n",
    "# Fill forward for OHLC data\n",
    "# ohlc_columns = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "# for col_name in ohlc_columns:\n",
    "#     # Create a window specification to fill forward based on timestamp\n",
    "#     window_spec = Window.orderBy(\"Timestamp\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "#     # Fill forward using the last non-null value\n",
    "#     bitcoin_data = bitcoin_data.withColumn(col_name, last(col_name, ignorenulls=True).over(window_spec))\n",
    "\n",
    "# Fill forward for OHLC data    \n",
    "ohlc_columns = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "bitcoin_data_pd = bitcoin_data.toPandas() # Converting to pandas df since Spark function not working as expected \n",
    "for col_name in ohlc_columns:\n",
    "    bitcoin_data_pd[col_name].fillna(method='ffill', inplace=True)\n",
    "\n",
    "bitcoin_data = spark.createDataFrame(bitcoin_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "900986d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3375, 9)\n",
      "Columns: ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Weighted_Price', 'Date']\n",
      "Is There any 'NaN' value: False\n",
      "Is there any duplicate value: False\n"
     ]
    }
   ],
   "source": [
    "# Shape (Number of Rows, Number of Columns)\n",
    "num_rows = bitcoin_data.count()\n",
    "num_columns = len(bitcoin_data.columns)\n",
    "\n",
    "print(\"Shape: ({}, {})\".format(num_rows, num_columns))\n",
    "\n",
    "# Columns\n",
    "columns = bitcoin_data.columns\n",
    "print(\"Columns: {}\".format(columns))\n",
    "\n",
    "# Check for 'NaN' values\n",
    "has_nan = bitcoin_data.select([col(c).isNull().alias(c) for c in bitcoin_data.columns]).rdd.flatMap(lambda x: x).collect()\n",
    "any_nan = any(has_nan)\n",
    "\n",
    "print(\"Is There any 'NaN' value: {}\".format(any_nan))\n",
    "\n",
    "# Check for duplicate values\n",
    "has_duplicates = bitcoin_data.groupBy(bitcoin_data.columns).count().filter(\"count > 1\").count() > 0\n",
    "\n",
    "print(\"Is there any duplicate value: {}\".format(has_duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3035f",
   "metadata": {},
   "source": [
    "# Feature Engineering - Day of Week, 7 day prior information features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d56e383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Data Shape:  3368\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# You can add features like day of the week, hour of the day, etc.\n",
    "bitcoin_data = bitcoin_data.withColumn(\"DayOfWeek\", dayofweek(\"Timestamp\"))\n",
    "bitcoin_data = bitcoin_data.withColumn(\"HourOfDay\", hour(\"Timestamp\"))\n",
    "\n",
    "# Getting more features, last 7 days information to help predict next day closing (can increase more)\n",
    "\n",
    "# Define the window specification\n",
    "window_spec = Window().orderBy(\"Timestamp\")\n",
    "\n",
    "lag_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume_(BTC)\", \"Volume_(Currency)\"]\n",
    "\n",
    "# Create lagged features for the last 7 days\n",
    "for i in lag_cols:\n",
    "    for j in range(1,8):\n",
    "        bitcoin_data = bitcoin_data.withColumn(col_name + \"_b_\" + str(j), lag(col_name, j).over(window_spec))\n",
    "\n",
    "bitcoin_data = bitcoin_data.dropna() # drop the first rows. They don't have previous information \n",
    "print(\"Updated Data Shape: \", bitcoin_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "119ac24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|          Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|      Date|DayOfWeek|HourOfDay|Close_b_1|Close_b_2|Close_b_3|Close_b_4|Close_b_5|Close_b_6|Close_b_7|\n",
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|2012-01-07 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-07|        7|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-08 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-08|        1|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-09 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-09|        2|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-10 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-10|        3|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-11 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-11|        4|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-12 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-12|        5|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-13 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-13|        6|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-14 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-14|        7|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-15 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-15|        1|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "|2012-01-16 00:00:00|4.39|4.39|4.39| 4.39|         0.0|              0.0|           0.0|2012-01-16|        2|        0|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|     4.39|\n",
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bitcoin_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7488b9d",
   "metadata": {},
   "source": [
    "# Generate the Prediction label as next day close value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61c35d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated record count after adding prediction close label: 3367\n"
     ]
    }
   ],
   "source": [
    "# Add next closing value as a label for prediction label\n",
    "window_spec = Window().orderBy(\"Timestamp\")\n",
    "\n",
    "bitcoin_data = bitcoin_data.withColumn(\"upcoming_close\", lag('Close', -1).over(window_spec))\n",
    "\n",
    "bitcoin_data = bitcoin_data.dropna() # drop the last row. It doesn't have next information \n",
    "print(\"Updated record count after adding prediction close label:\", bitcoin_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad32c963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Timestamp',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Volume_(BTC)',\n",
       " 'Volume_(Currency)',\n",
       " 'Weighted_Price',\n",
       " 'Date',\n",
       " 'DayOfWeek',\n",
       " 'HourOfDay',\n",
       " 'Close_b_1',\n",
       " 'Close_b_2',\n",
       " 'Close_b_3',\n",
       " 'Close_b_4',\n",
       " 'Close_b_5',\n",
       " 'Close_b_6',\n",
       " 'Close_b_7',\n",
       " 'upcoming_close']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479fc428",
   "metadata": {},
   "source": [
    "# Generate the Feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "114a3d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|          Attributes|upcoming_close|\n",
      "+--------------------+--------------+\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          4.39|\n",
      "|[4.39,4.39,4.39,4...|          6.01|\n",
      "|[6.01,6.01,6.01,6...|          6.01|\n",
      "|[6.01,6.01,6.01,6...|          6.01|\n",
      "|[6.01,6.01,6.01,6...|          6.01|\n",
      "|[6.01,6.01,6.01,6...|          6.01|\n",
      "|[6.01,6.01,6.01,6...|          6.01|\n",
      "|[6.01,6.01,6.01,6...|           6.0|\n",
      "|[6.09,6.09,6.0,6....|           6.0|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Input all the features in one vector column\n",
    "feature_columns = [i for i in bitcoin_data.columns if i not in ['upcoming_close', 'Date', 'Timestamp']]\n",
    "assembler = VectorAssembler(inputCols= feature_columns, outputCol = 'Attributes')\n",
    "\n",
    "output = assembler.transform(bitcoin_data) #transform the data using Vector Assembler\n",
    "\n",
    "#Input vs Output\n",
    "finalized_data = output.select(\"Attributes\",\"upcoming_close\")\n",
    "\n",
    "finalized_data.show() # showing the final data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394a8d5",
   "metadata": {},
   "source": [
    "# Feature Vector and Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e6d8549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% test data = % 10.008910008910009\n",
      "Train data records: 3030\n",
      "Test data records: 337\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "feature_columns = [i for i in bitcoin_data.columns if i not in ['upcoming_close', 'Date', 'Timestamp', 'HourOfDay']]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "# bitcoin_data = assembler.transform(bitcoin_data)\n",
    "\n",
    "# Train-Test Split - since the problem is time series, we should perform the sequenctial split\n",
    "prediction_days = int(np.round(bitcoin_data.count()*(10/100),0))\n",
    "train_data = bitcoin_data.limit(int(bitcoin_data.count()-prediction_days))\n",
    "test_data = bitcoin_data.exceptAll(train_data)\n",
    "\n",
    "print(\"% test data = %\", (prediction_days/int(bitcoin_data.count())) * 100)\n",
    "print(\"Train data records:\", train_data.count())\n",
    "print(\"Test data records:\", test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336622ba",
   "metadata": {},
   "source": [
    "# Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5672dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"upcoming_close\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# Model Training\n",
    "model_lr = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56b60d",
   "metadata": {},
   "source": [
    "# Model Evaluation using RMSE and R2 - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32fef2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1260.6665093920308\n",
      "R2: 0.9934691260305369\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model_lr.transform(test_data)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"upcoming_close\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"upcoming_close\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(f\"R2: {r2}\")\n",
    "\n",
    "# # View Predictions\n",
    "# predictions.select(\"Close\", \"prediction\", *feature_columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe0b6d",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f5b4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"upcoming_close\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Model Training\n",
    "model_rf = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc8417",
   "metadata": {},
   "source": [
    "# Model Evaluation using RMSE and R2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "563129a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 16995.15992452752\n",
      "R2: -0.1869198227710125\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model_rf.transform(test_data)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"upcoming_close\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"upcoming_close\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(f\"R2: {r2}\")\n",
    "\n",
    "# # View Predictions\n",
    "# predictions.select(\"Close\", \"prediction\", *feature_columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab6427",
   "metadata": {},
   "source": [
    "# Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "221eb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"upcoming_close\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, gbt])\n",
    "\n",
    "# Model Training\n",
    "model_gbt = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552195a",
   "metadata": {},
   "source": [
    "# Model Evaluation using RMSE and R2 - GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52fa1dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 16015.088058957046\n",
      "R2: -0.05397311689097095\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model_gbt.transform(test_data)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"upcoming_close\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"upcoming_close\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(f\"R2: {r2}\")\n",
    "\n",
    "# # View Predictions\n",
    "# predictions.select(\"Close\", \"prediction\", *feature_columns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed83ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
